{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3950bea4",
   "metadata": {},
   "source": [
    "# Cogito Computer Vision Course\n",
    "\n",
    "Welcome to the Cogito Computer Vision Course!\n",
    "\n",
    "One can either run the code here locally, or in a Google Colab notebook: https://colab.research.google.com/github/CogitoNTNU/course-computer-vision/blob/main/course.ipynb \n",
    "\n",
    "In this course you will learn about the fundamentals of computer vision, including image processing, feature extraction, and object classification.\n",
    "An additional resource for learning about convolutional neural networks (CNNs) can be found in [this link](https://poloclub.github.io/cnn-explainer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3751dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31afdb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "dataset = datasets.FashionMNIST(root='data', train=True, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570eecd",
   "metadata": {},
   "source": [
    "# Fashion MNIST\n",
    "A dataset of fashion images, to practice computer vision. The dataset contains 60,000 training images and 10,000 test images of clothing items, such as shirts, shoes, and bags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.classes\n",
    "print(\"The class names are: \", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd7071",
   "metadata": {},
   "source": [
    "Lets look at a picture from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8dbc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image, first_label = dataset[0]\n",
    "img = first_image.numpy().transpose((1, 2, 0))\n",
    "print(f\"This is a {class_names[first_label]}\")\n",
    "print(f\"The shape of the image is {img.shape}\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c023fe9",
   "metadata": {},
   "source": [
    "# Max Pooling\n",
    "We can also apply max pooling to the image. Max pooling is a downsampling technique that reduces the spatial dimensions of the image, while retaining the most important features. Here, we use a kernel size of 2 and a stride of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset[0][0].unsqueeze(0)  # Add batch dimension\n",
    "pool = torch.nn.MaxPool2d(kernel_size=2, stride=4)\n",
    "pooled_img = pool(img)\n",
    "plt.imshow(pooled_img.squeeze(0).permute(1, 2, 0).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804fa64",
   "metadata": {},
   "source": [
    "This can be done multiple times. You can see how the image gets smaller and smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce2948",
   "metadata": {},
   "outputs": [],
   "source": [
    "dobbel_pooled = pool(pooled_img)\n",
    "plt.imshow(dobbel_pooled.squeeze(0).permute(1, 2, 0).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0222f95c",
   "metadata": {},
   "source": [
    "# CNN Filters\n",
    "Lets look at the filters in a convolutional neural network. Here is an example picture of a cat: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d697105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "url = \"https://cdn.britannica.com/70/234870-050-D4D024BB/Orange-colored-cat-yawns-displaying-teeth.jpg\"\n",
    "\n",
    "# Download the image\n",
    "response = requests.get(url)\n",
    "image = plt.imread(BytesIO(response.content), format=\"jpg\")\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e5f52",
   "metadata": {},
   "source": [
    "If we apply a filter to the image, we can see how it highlights certain features. For example, a filter that detects edges will highlight the edges in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = torch.tensor([[[[-1, -1, -1],\n",
    "                         [-1,  8, -1],\n",
    "                         [-1, -1, -1]]]], dtype=torch.float32)  # Edge detection filter\n",
    "conv_layer = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, padding=1, bias=False)\n",
    "relu_layer = torch.nn.ReLU()\n",
    "conv_layer.weight = torch.nn.Parameter(filter.repeat(1, 3, 1, 1))  # Repeat filter for 3 input channels\n",
    "image_tensor = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).float()  # Add batch dimension and convert to float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b451e",
   "metadata": {},
   "source": [
    "Without Relu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab1996",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_image = conv_layer(image_tensor)\n",
    "plt.imshow(filtered_image.squeeze(0).permute(1, 2, 0).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416bd513",
   "metadata": {},
   "source": [
    "With Relu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a526f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_image = conv_layer(image_tensor)\n",
    "filtered_image = relu_layer(filtered_image)\n",
    "plt.imshow(filtered_image.squeeze(0).permute(1, 2, 0).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6bc8a",
   "metadata": {},
   "source": [
    "# Task 1 - Experiment with Filters\n",
    "We can see how another filter might affect the image. Try to change the filter values and see how it affects the image.\n",
    "\n",
    "Here are some examples of filters:\n",
    "![image.png](https://miro.medium.com/v2/resize:fit:1400/1*UaO9cemImbhwMVQOoUTPLQ.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c003662",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = torch.tensor([[[[ 0, 1, 0],\n",
    "                         [-1, 1, 1],\n",
    "                         [ 0, 0, 1]]]], dtype=torch.float32)  # Another filter\n",
    "conv_layer.weight = torch.nn.Parameter(filter.repeat(1, 3, 1, 1))  # Repeat filter for 3 input channels\n",
    "filtered_image = conv_layer(image_tensor)\n",
    "filtered_image = relu_layer(filtered_image)\n",
    "plt.imshow(filtered_image.squeeze(0).permute(1, 2, 0).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2be80",
   "metadata": {},
   "source": [
    "# Task 2 - Explore Data Augmentation\n",
    "\n",
    "Uncomment a transformation and run the cell to see what it does. You can experiment with the parameter values too, if you like. (The factor parameters should be greater than 0 and, generally, less than 1.) Run the cell again if you'd like to get a new random image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becfd12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomVerticalFlip, RandomRotation, ColorJitter, GaussianBlur, RandomResizedCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to change some of the parameters below and see how the image changes. Also try to add/remove transforms.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    RandomVerticalFlip(p=0.5),\n",
    "    RandomRotation(degrees=30),\n",
    "    RandomResizedCrop(size=128, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "    ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "])\n",
    "dataset = datasets.FashionMNIST(root='data', train=True, download=True, transform=transform)\n",
    "image, label = dataset[0]\n",
    "plt.imshow(image.permute(1, 2, 0).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6029a70c",
   "metadata": {},
   "source": [
    "# Create a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ac4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device) # The device should be CUDA\n",
    "\n",
    "class_names = dataset.classes\n",
    "# Create a model\n",
    "model = Sequential(\n",
    "    Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "    MaxPool2d(kernel_size=2, stride=2),\n",
    "    Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "    MaxPool2d(kernel_size=2, stride=2),\n",
    "    Flatten(),\n",
    "    Linear(in_features=32*32*32, out_features=128),\n",
    "    Linear(in_features=128, out_features=10)\n",
    ").to(device)\n",
    "# Test the model with the first image\n",
    "img = dataset[0][0].unsqueeze(0).to(device)  # Add batch dimension\n",
    "output = model(img)\n",
    "predicted_class = torch.argmax(output, dim=1).item()\n",
    "print(f\"The model predicts this image as a {class_names[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c140942",
   "metadata": {},
   "source": [
    "This model is not trained, so the output will be random. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b4eb4",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "Below is an example of how to train a model on the Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6019c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(root='data/FashionMNIST', train=True, download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root='data/FashionMNIST', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Training on batch number: {i}\")\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b171bb",
   "metadata": {},
   "source": [
    "We can then evaluate the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "model.eval()\n",
    "for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test images: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5812982f",
   "metadata": {},
   "source": [
    "# Task 3 - Design your own model\n",
    "Now you can try to create your own model and train it on the Fashion MNIST dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3af7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    # Design your own model\n",
    ").to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    # Add your data augmentations here\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# You may change these values\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81909423",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ec2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9a5ad",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "model.eval()\n",
    "for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test images: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
