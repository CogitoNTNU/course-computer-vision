{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3751dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31afdb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "dataset = datasets.FashionMNIST(root='data', train=True, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570eecd",
   "metadata": {},
   "source": [
    "# Fashion MNIST\n",
    "A dataset of fashion images, to practice computer vision. The dataset contains 60,000 training images and 10,000 test images of clothing items, such as shirts, shoes, and bags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.classes\n",
    "print(\"The class names are: \", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd7071",
   "metadata": {},
   "source": [
    "Lets look at a picture from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8dbc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image, first_label = dataset[0]\n",
    "img = first_image.numpy().transpose((1, 2, 0))\n",
    "print(f\"This is a {class_names[first_label]}\")\n",
    "print(f\"The shape of the image is {img.shape}\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a487adc",
   "metadata": {},
   "source": [
    "See what pooling does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset[0][0].unsqueeze(0)  # Add batch dimension\n",
    "pool = torch.nn.MaxPool2d(kernel_size=2, stride=4)\n",
    "pooled_img = pool(img)\n",
    "plt.imshow(pooled_img.squeeze(0).permute(1, 2, 0).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804fa64",
   "metadata": {},
   "source": [
    "This can be done multiple times. You can see how the image gets smaller and smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce2948",
   "metadata": {},
   "outputs": [],
   "source": [
    "dobbel_pooled = pool(pooled_img)\n",
    "plt.imshow(dobbel_pooled.squeeze(0).permute(1, 2, 0).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0222f95c",
   "metadata": {},
   "source": [
    "# CNN Filters\n",
    "Lets look at the filters in a convolutional neural network. Here is an example picture of a cat: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d697105",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/cat.png\"\n",
    "image = plt.imread(image_path)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e5f52",
   "metadata": {},
   "source": [
    "If we apply a filter to the image, we can see how it highlights certain features. For example, a filter that detects edges will highlight the edges in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = torch.tensor([[[[-1, -1, -1],\n",
    "                                 [-1,  8, -1],\n",
    "                                 [-1, -1, -1]]]], dtype=torch.float32)  # Edge detection filter\n",
    "conv_layer = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, padding=1, bias=False)\n",
    "relu_layer = torch.nn.ReLU()\n",
    "conv_layer.weight = torch.nn.Parameter(filter.repeat(1, 3, 1, 1))  # Repeat filter for 3 input channels\n",
    "image_tensor = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).float()  # Add batch dimension and convert to float\n",
    "filtered_image = conv_layer(image_tensor)\n",
    "filtered_image = relu_layer(filtered_image)\n",
    "\n",
    "plt.imshow(filtered_image.squeeze(0).permute(1, 2, 0).detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6bc8a",
   "metadata": {},
   "source": [
    "We can see how another filter might affect the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c003662",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = torch.tensor([[[[1, 0, -1],\n",
    "                                 [1, 0, -1],\n",
    "                                 [1, 0, -1]]]], dtype=torch.float32)  # Another filter\n",
    "conv_layer.weight = torch.nn.Parameter(filter.repeat(1, 3, 1, 1))  # Repeat filter for 3 input channels\n",
    "filtered_image = conv_layer(image_tensor)\n",
    "filtered_image = relu_layer(filtered_image)\n",
    "plt.imshow(filtered_image.squeeze(0).permute(1, 2, 0).detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6029a70c",
   "metadata": {},
   "source": [
    "# Create a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ac4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential\n",
    "import torch\n",
    "\n",
    "class_names = dataset.classes\n",
    "# Create a model\n",
    "model = Sequential(\n",
    "    Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "    MaxPool2d(kernel_size=2, stride=2),\n",
    "    Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "    MaxPool2d(kernel_size=2, stride=2),\n",
    "    Flatten(),\n",
    "    Linear(in_features=32 * 32 * 32, out_features=128),\n",
    "    Linear(in_features=128, out_features=10)\n",
    ")\n",
    "# Test the model with the first image\n",
    "img = dataset[0][0].unsqueeze(0)  # Add batch dimension\n",
    "output = model(img)\n",
    "predicted_class = torch.argmax(output, dim=1).item()\n",
    "print(f\"The model predicts this image as a {class_names[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e584404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kurs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
